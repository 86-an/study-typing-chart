import os
os.environ["OMP_NUM_THREADS"] = "3"

import mkl
mkl.set_num_threads(3)  # ğŸ”¹ MKL ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’æ˜ç¤ºçš„ã« 3 ã«è¨­å®š


import multiprocessing
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openpyxl import Workbook, load_workbook
from openpyxl.drawing.image import Image
from openpyxl.utils import get_column_letter  # åˆ—å¹…èª¿æ•´ç”¨
from PIL import Image as PILImage  # Pillow ã‚’è¿½åŠ 
import matplotlib.dates as mdates
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from sklearn.tree import DecisionTreeRegressor



# ğŸ“Œ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams["font.family"] = "Meiryo"



class TypingDataProcessor:
    """ ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€çµ±è¨ˆè¨ˆç®—ã¨ã‚°ãƒ©ãƒ•åŒ–ã‚’è¡Œã†è¦ªã‚¯ãƒ©ã‚¹ """

    def __init__(self, file_path, sheet_name, usecols, columns, image_name):
        """ åˆæœŸåŒ–: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ """
        self.file_path = file_path
        self.sheet_name = sheet_name
        self.columns = columns
        self.image_name = image_name
        self.df = self.load_data(usecols)
        self.wb = None
        self.add_dates()
        self.process_data()
        self.calculate_stats()
        self.calculate_recent_stats()
    
    def make_excel(self):
        # "data_analysis.xlsx"ã‚’æ–°ã—ãä½œæˆ
        if not os.path.exists("data_analysis.xlsx"):
            self.wb = Workbook()
            self.wb.save("data_analysis.xlsx")
        else:
            os.remove("data_analysis.xlsx")
            self.wb = Workbook()
            self.wb.save("data_analysis.xlsx")

    # åˆ—åã®åˆ‡ã‚Šåˆ†ã‘
    def get_feature_columns_for_regression(self):
        """ å›å¸°åˆ†æã«ä½¿ã†ç‰¹å¾´é‡ã®ã‚«ãƒ©ãƒ åã‚’è¿”ã™ """
        if "ç·æ­£æ‰“æ•°" in self.df.columns:
            return ["ç·æ­£æ‰“æ•°", "æ­£æ‰“ç‡"]
        elif "å¹³å‡é€Ÿåº¦" in self.df.columns:
            return ["å¹³å‡é€Ÿåº¦", "æ­£æ‰“ç‡"]
        else:
            return ["æ­£æ‰“ç‡"]  # æœ€ä½é™

    def get_target_column(self):
        return "ã‚¹ã‚³ã‚¢"
    
    def load_data(self, usecols):
        """ Excelãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ç©ºç™½ã‚»ãƒ«ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç† """
        df = pd.read_excel(self.file_path, sheet_name=self.sheet_name, usecols=usecols)
        last_valid_index = df.dropna(how="all").index[-1]
        return df.loc[:last_valid_index].copy()

    def add_dates(self):
            """ æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€DataFrameã«è¿½åŠ  """
            dates = pd.read_excel(self.file_path, sheet_name=self.sheet_name, usecols="A", skiprows=1, nrows=len(self.df), header=None)
            dates.columns = ["æ—¥ä»˜"]

            # æ—¥ä»˜åˆ—ã®å‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ•°å€¤ï¼ˆExcelã®ã‚·ãƒªã‚¢ãƒ«å€¤ï¼‰ã®ã¿ã‚’å¤‰æ›ã™ã‚‹
            dates["æ—¥ä»˜"] = dates["æ—¥ä»˜"].apply(
                lambda x: pd.to_datetime(x - 2, origin="1899-12-30", unit="D")
                if isinstance(x, (float, int))
                else pd.to_datetime(x)
            )
            
            self.df.insert(0, "æ—¥ä»˜", dates["æ—¥ä»˜"])
            self.df.set_index("æ—¥ä»˜", inplace=True)

    def calculate_stats(self):
        self.df_week = self.df.resample("W").agg(["median", "mean", "max", "min"])
        self.df_month = self.df.resample("ME").agg(["median", "mean", "max", "min"])

    def calculate_recent_stats(self):
        """ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãƒ»ç›´è¿‘14æ—¥é–“ãƒ»60æ—¥é–“ã®çµ±è¨ˆã‚’è¨ˆç®—ï¼ˆå„é …ç›®ã”ã¨ï¼‰ """
    
        # ğŸ“Œ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€çµ‚2è¡Œï¼‰
        self.df_latest = self.df.tail(2)
    
        # ğŸ“Œ ç›´è¿‘14æ—¥é–“ãƒ»60æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿
        self.df_last14 = self.df.tail(14)
        self.df_last60 = self.df.tail(60)
    
        # ğŸ“Œ ç›´è¿‘14æ—¥é–“ãƒ»60æ—¥é–“ã®çµ±è¨ˆã‚’è¨ˆç®—ï¼ˆå„ã‚«ãƒ©ãƒ ã”ã¨ï¼‰
        self.stats_last14 = self.df_last14[self.columns].agg(["median", "mean", "max", "min"])
        self.stats_last60 = self.df_last60[self.columns].agg(["median", "mean", "max", "min"])
    
        # ğŸ“Œ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®é †ä½ï¼ˆ2ã¤å–å¾—ï¼‰
        self.latest_rank = {}
        for col in self.columns:
            latest_value_1 = self.df_latest[col].iloc[0]  # æœ€æ–°ãƒ‡ãƒ¼ã‚¿1
            latest_value_2 = self.df_latest[col].iloc[1]  # æœ€æ–°ãƒ‡ãƒ¼ã‚¿2
            rank_1 = (self.df[col] > latest_value_1).sum() + 1
            rank_2 = (self.df[col] > latest_value_2).sum() + 1
            total_records = len(self.df)
            self.latest_rank[col] = [f"{rank_1} ä½ / {total_records} ä½", f"{rank_2} ä½ / {total_records} ä½"]
    
        print("ğŸ“Œ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆ2ã¤ï¼‰:", self.df_latest)
        print("ğŸ“Œ ç›´è¿‘14æ—¥é–“ã®çµ±è¨ˆ:", self.stats_last14)
        print("ğŸ“Œ ç›´è¿‘60æ—¥é–“ã®çµ±è¨ˆ:", self.stats_last60)
        print("ğŸ“Œ æœ€æ–°é †ä½:", self.latest_rank)

    def process_data(self):
        pass  # âœ… ç¶™æ‰¿å…ˆã§å€‹åˆ¥å‡¦ç†ã‚’å®šç¾©ã™ã‚‹

    def plot_graphs(self):
        """ ğŸ“Š ã‚°ãƒ©ãƒ•ä½œæˆ: ç¸¦3Ã—æ¨ª1ã®å…¨ãƒ‡ãƒ¼ã‚¿æ¨ç§» & é€±ãƒ»æœˆæ¯”è¼ƒï¼ˆPNGã¨ã—ã¦ä¿å­˜ï¼‰ """
    
        # ğŸ“Œ 1. é€±ãƒ»æœˆæ¯”è¼ƒã®ã‚°ãƒ©ãƒ•ï¼ˆ3 Ã— 2 ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
        fig, axes_week_month = plt.subplots(nrows=3, ncols=2, figsize=(12, 16), sharex=True)
    
        for i, col in enumerate(self.columns):
            # ğŸ“Œ é€±å˜ä½ã®çµ±è¨ˆ
            axes_week_month[i, 0].plot(self.df_week.index, self.df_week.loc[:, (col, "median")], label=f"{col}ï¼ˆä¸­å¤®å€¤ï¼‰", linestyle="--", color="blue")
            axes_week_month[i, 0].plot(self.df_week.index, self.df_week.loc[:, (col, "mean")], label=f"{col}ï¼ˆå¹³å‡ï¼‰", linestyle="-", color="green")
            axes_week_month[i, 0].plot(self.df_week.index, self.df_week.loc[:, (col, "max")], label=f"{col}ï¼ˆæœ€å¤§ï¼‰", linestyle=":", color="red")
            axes_week_month[i, 0].plot(self.df_week.index, self.df_week.loc[:, (col, "min")], label=f"{col}ï¼ˆæœ€å°ï¼‰", linestyle="-.", color="purple")
        
            axes_week_month[i, 0].set_title(f"é€±ã”ã¨ã® {col}")
            axes_week_month[i, 0].legend()
        
            # ğŸ“Œ æœˆå˜ä½ã®çµ±è¨ˆ
            axes_week_month[i, 1].plot(self.df_month.index, self.df_month.loc[:, (col, "median")], label=f"{col}ï¼ˆä¸­å¤®å€¤ï¼‰", linestyle="--", color="blue")
            axes_week_month[i, 1].plot(self.df_month.index, self.df_month.loc[:, (col, "mean")], label=f"{col}ï¼ˆå¹³å‡ï¼‰", linestyle="-", color="green")
            axes_week_month[i, 1].plot(self.df_month.index, self.df_month.loc[:, (col, "max")], label=f"{col}ï¼ˆæœ€å¤§ï¼‰", linestyle=":", color="red")
            axes_week_month[i, 1].plot(self.df_month.index, self.df_month.loc[:, (col, "min")], label=f"{col}ï¼ˆæœ€å°ï¼‰", linestyle="-.", color="purple")
        
            axes_week_month[i, 1].set_title(f"æœˆã”ã¨ã® {col}")
            axes_week_month[i, 1].legend()
    
        # ğŸ“Œ 2. å…¨ãƒ‡ãƒ¼ã‚¿æ¨ç§»ã®ã‚°ãƒ©ãƒ•ï¼ˆç¸¦3Ã—æ¨ª1ï¼‰
        fig_all, axes_all = plt.subplots(nrows=len(self.columns), ncols=1, figsize=(10, 12), sharex=True)
    
        for i, col in enumerate(self.columns):
            axes_all[i].plot(self.df.index, self.df[col], label=f"{col} å…¨ãƒ‡ãƒ¼ã‚¿", color="blue")
            axes_all[i].set_title(f"{col} ã®æ¨ç§»")
            axes_all[i].legend()
    
        # ğŸ“Œ Xè»¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’çµ±ä¸€
        first_date = self.df.index.min()
        last_date = self.df.index.max()
        middle_date = self.df.index[int(len(self.df) / 2)]
        tick_dates = [first_date, middle_date, last_date]
    
        for ax in axes_week_month.flatten():
            ax.set_xticks(tick_dates)
            ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y/%m/%d"))
    
        for ax in axes_all:
            ax.set_xticks(tick_dates)
            ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y/%m/%d"))
    
        fig.suptitle(f"{self.sheet_name} ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿", fontsize=16)
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    
        # ğŸ“Œ 3. ä¸¡æ–¹ã®ã‚°ãƒ©ãƒ•ã‚’1ã¤ã®ç”»åƒã«çµ±åˆã—ã¦ä¿å­˜
        fig.savefig("temp_week_month.png")
        img_week_month = PILImage.open("temp_week_month.png")
    
        fig_all.savefig("temp_all.png", bbox_inches="tight")
        img_all = PILImage.open("temp_all.png")
    
        new_height = img_week_month.height + img_all.height
        new_width = max(img_week_month.width, img_all.width)
        new_image = PILImage.new("RGB", (new_width, new_height), "white")
    
        new_image.paste(img_week_month, (0, 0))
        new_image.paste(img_all, (0, img_week_month.height))
    
        new_image.save(self.image_name)
    
        os.remove("temp_week_month.png")
        os.remove("temp_all.png")
    
        plt.close(fig)
        plt.close(fig_all)
        print(f"{self.image_name}ã«æˆåŠŸï¼")
    
        # ğŸ“Œ Excel ã«ç”»åƒã‚’è²¼ã‚Šä»˜ã‘ã‚‹å‡¦ç†ã‚’è¿½åŠ 
        self.wb = load_workbook("data_analysis.xlsx")
        ws_data_analysis = self.wb.create_sheet(f"{self.image_name} ã‚°ãƒ©ãƒ•")
    
        # ğŸ“Œ ç¸®å°ã—ãŸ PNGç”»åƒã‚’ãƒ­ãƒ¼ãƒ‰
        img = Image(f"{self.image_name}")
    
        # ğŸ“Œ ç”»åƒã‚’ A1 ã«é…ç½®
        ws_data_analysis.add_image(img, "A1")
    
        # ğŸ“Œ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        self.wb.save("data_analysis.xlsx")
        
    def plot_summary_table(self):
        """ ğŸ“Š å„é …ç›®ã®çµ±è¨ˆæƒ…å ±ï¼ˆæœ€æ–°é †ä½ï¼ˆ2ã¤ï¼‰ãƒ»ç›´è¿‘14æ—¥é–“ãƒ»60æ—¥é–“ãƒ»å…¨ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’**1æšã®è¡¨ã«ã¾ã¨ã‚ã¦**è¡¨ç¤ºï¼†ä¿å­˜ """
    
        headers = ["é …ç›®"] + self.columns
        data = []
    
        # ğŸ“Œ çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆå„ã‚«ãƒ©ãƒ ã”ã¨ã«å€¤ã‚’æƒãˆã‚‹ï¼‰
        metrics = {"median": "ä¸­å¤®å€¤", "mean": "å¹³å‡", "min": "æœ€å°å€¤", "max": "æœ€å¤§å€¤"}
        periods = {"self.df": "å…¨ãƒ‡ãƒ¼ã‚¿", "self.df_last14": "ç›´è¿‘14æ—¥é–“", "self.df_last60": "ç›´è¿‘60æ—¥é–“"}
    
        for df_key, period_name in periods.items():
            df_period = eval(df_key)  # `self.df`, `self.df_last14`, `self.df_last60` ã‚’å–å¾—
            for metric, metric_jp in metrics.items():
                row = [f"{period_name}ã®{metric_jp}"] + [df_period[col].agg(metric) for col in self.columns]
                data.append(row)
    
            data.append([""] * len(headers))  # ç©ºè¡Œã®åŒºåˆ‡ã‚Šï¼ˆæ­£ã—ãåˆ—æ•°ã‚’æƒãˆã‚‹ï¼‰
    
        # ğŸ“Œ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®é †ä½ï¼ˆ2ã¤ï¼‰
        rank_row_1 = ["æœ€æ–°ãƒ‡ãƒ¼ã‚¿é †ä½ï¼ˆ1ã¤ç›®ï¼‰"] + [self.latest_rank[col][0] for col in self.columns]
        rank_row_2 = ["æœ€æ–°ãƒ‡ãƒ¼ã‚¿é †ä½ï¼ˆ2ã¤ç›®ï¼‰"] + [self.latest_rank[col][1] for col in self.columns]
        data.append(rank_row_1)
        data.append(rank_row_2)
    
        data.append([""] * len(headers))  # ç©ºè¡Œã‚’è¿½åŠ 


        """ ğŸ“Œ data_analysis.xlsx ã«è¡¨ãƒ‡ãƒ¼ã‚¿ã¨ã‚°ãƒ©ãƒ•ã‚’åˆ¥ã‚·ãƒ¼ãƒˆã§ä¿å­˜ """
        self.wb = load_workbook("data_analysis.xlsx")
        ws_data = self.wb.create_sheet(f"{self.sheet_name}ã®è¡¨")
        
        # ğŸ“Œ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ¼ãƒˆã«æ›¸ãè¾¼ã‚€
        for r_idx, row in enumerate(data, start=1):
            for c_idx, value in enumerate(row, start=1):
                ws_data.cell(row=r_idx, column=c_idx, value=value)

        # ğŸ“Œ åˆ—å¹…ã®æœ€é©åŒ–
        for col in ws_data.columns:
            max_length = 0
            column = col[0].column_letter
            for cell in col:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(cell.value)
                except:
                    pass
            adjusted_width = (max_length + 1) * 2
            ws_data.column_dimensions[column].width = adjusted_width

        # ğŸ“Œ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        self.wb.save("data_analysis.xlsx")

    def analysis_trend_related(self):
        # ğŸ“Œ Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        self.wb = load_workbook("data_analysis.xlsx")
        sheet_name = f"{self.image_name} ç›¸é–¢ã¨å›å¸°"
        ws_data_analysis = self.wb.create_sheet(sheet_name)
    
        # ğŸ”¹ **ç›¸é–¢ä¿‚æ•°ã®å‡ºåŠ›ï¼ˆè¡¨å½¢å¼ï¼‰**
        ws_data_analysis.append(["ç›¸é–¢ä¿‚æ•°"])
        correlation_matrix = self.df[self.columns].corr()
    
        # **ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ **
        ws_data_analysis.append([""] + list(correlation_matrix.columns))
        
        # **è¡Œã”ã¨ã®ãƒ‡ãƒ¼ã‚¿è¿½åŠ **
        for index, row in correlation_matrix.iterrows():
            ws_data_analysis.append([index] + list(row))
    
        # **1è¡Œç©ºã‘ã‚‹**
        ws_data_analysis.append([])
    
        # ğŸ”¹ **ãƒ‡ãƒ¼ã‚¿ã®ã°ã‚‰ã¤ã**
        ws_data_analysis.append(["æ¨™æº–åå·®"])
        std_values = {
            self.columns[0]: np.std(self.df[self.columns[0]]),
            self.columns[1]: np.std(self.df[self.columns[1]]),
            self.columns[2]: np.std(self.df[self.columns[2]])
        }
    
        for key, value in std_values.items():
            ws_data_analysis.append([key, value])
    
        # **1è¡Œç©ºã‘ã‚‹**
        ws_data_analysis.append([])
    
        # ğŸ”¹ **å›å¸°åˆ†æ**
        ws_data_analysis.append(["å›å¸°åˆ†æ"])
        
        X = self.df[[self.columns[0], self.columns[2]]]
        y = self.df[self.columns[1]]
 
        model = LinearRegression()
        model.fit(X, y)
    
        ws_data_analysis.append([f"{self.columns[0]} â†’ {self.columns[1]}", model.coef_[0]])
        ws_data_analysis.append([f"{self.columns[2]} â†’ {self.columns[1]}", model.coef_[1]])
        ws_data_analysis.append([f"{self.columns[1]}ã®æ±ºå®šä¿‚æ•° (RÂ²)", model.score(X, y)])
    
        # **1è¡Œç©ºã‘ã‚‹**
        ws_data_analysis.append([])
    
        # ğŸ”¹ **æ­£æ‰“ç‡ã¨ç·æ­£æ‰“æ•°ã®é–¢ä¿‚åˆ†æ**
        rate_X = self.df[[self.columns[2]]]  
        rate_y = self.df[self.columns[0]]  
        rate_model = LinearRegression()
        rate_model.fit(rate_X, rate_y)
    
        ws_data_analysis.append([f"{self.columns[2]} â†’ {self.columns[1]}", rate_model.coef_[0]])
        ws_data_analysis.append([f"{self.columns[2]}ã®æ±ºå®šä¿‚æ•° (RÂ²)", rate_model.score(rate_X, rate_y)])
    
        # **1è¡Œç©ºã‘ã‚‹**
        ws_data_analysis.append([])
    
        # ğŸ”¹ **ã‚¹ã‚³ã‚¢äºˆæ¸¬**
        ws_data_analysis.append(["ã‚¹ã‚³ã‚¢äºˆæ¸¬"])
        new_data = pd.DataFrame({self.columns[0]: [600], self.columns[2]: [98]})
        predicted_score = model.predict(new_data)[0]
        ws_data_analysis.append(["äºˆæ¸¬ã‚¹ã‚³ã‚¢", predicted_score])
    
        # ğŸ“Š **ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆ**
        fig, axes = plt.subplots(3, 1, figsize=(8, 12))
        axes[0].hist(self.df[self.columns[1]], bins=5, alpha=0.5, color="blue")
        axes[0].set_title(f"{self.columns[1]}ã®åˆ†å¸ƒ")
        axes[1].hist(self.df[self.columns[2]], bins=5, alpha=0.5, color="green")
        axes[1].set_title(f"{self.columns[2]}ã®åˆ†å¸ƒ")
        axes[2].hist(self.df[self.columns[0]], bins=5, alpha=0.5, color="red")
        axes[2].set_title(f"{self.columns[0]}ã®åˆ†å¸ƒ")
    
        plt.tight_layout()
        graph_path = "hist.png"
        plt.savefig(graph_path, dpi=300, bbox_inches="tight")
        plt.close()
    
        # ğŸ“‚ **ã‚°ãƒ©ãƒ•ã‚’Excelã‚·ãƒ¼ãƒˆã«è¿½åŠ **
        img = PILImage.open(graph_path)
        new_size = (img.width // 4, img.height // 4)
        resized_img = img.resize(new_size)
        resized_img.save(f"{graph_path}_resized.png")
        img = Image(f"{graph_path}_resized.png")
        ws_data_analysis.add_image(img, "A23")
        # ğŸ“Œ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        self.wb.save("data_analysis.xlsx")
        print(f"Excelãƒ•ã‚¡ã‚¤ãƒ« {sheet_name} ã«ãƒ‡ãƒ¼ã‚¿ï¼†ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")

    def analysis_structure_features(self):
        os.environ["OMP_NUM_THREADS"] = "3"
        print(os.environ.get("OMP_NUM_THREADS"))  # ğŸ”¹ è¨­å®šãŒåæ˜ ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        print(multiprocessing.cpu_count())
        
        #ç§»å‹•å¹³å‡
        self.df["ã‚¹ã‚³ã‚¢_7æ—¥å¹³å‡"] = self.df[self.columns[1]].rolling(window=7).mean()
        self.df["ã‚¹ã‚³ã‚¢_30æ—¥å¹³å‡"] = self.df[self.columns[1]].rolling(window=30).mean()
        
        self.df.plot(y=["ã‚¹ã‚³ã‚¢", "ã‚¹ã‚³ã‚¢_7æ—¥å¹³å‡", "ã‚¹ã‚³ã‚¢_30æ—¥å¹³å‡"], figsize=(10, 5))
        plt.title("ã‚¹ã‚³ã‚¢ã®ç§»å‹•å¹³å‡")
        plt.close()

        #ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ
        X = self.df[self.columns]
        model = KMeans(n_clusters=3, n_init=10)
        self.df["ã‚¯ãƒ©ã‚¹ã‚¿"] = model.fit_predict(X)

        plt.scatter(self.df[self.columns[0]], self.df[self.columns[1]], c=self.df["ã‚¯ãƒ©ã‚¹ã‚¿"], cmap="viridis")
        plt.xlabel(self.columns[0])
        plt.ylabel(self.columns[1])
        plt.title(f"ã‚¹ã‚³ã‚¢ã¨{self.columns[0]}ã®ã‚¯ãƒ©ã‚¹ã‚¿åˆ†é¡")
        plt.close()
        print(self.df.groupby("ã‚¯ãƒ©ã‚¹ã‚¿").mean())

        plt.scatter(self.df[self.columns[2]], self.df[self.columns[1]], c=self.df["ã‚¯ãƒ©ã‚¹ã‚¿"], cmap="viridis")
        plt.xlabel(self.columns[2])
        plt.ylabel(self.columns[1])
        plt.title(f"{self.columns[1]}ã¨{self.columns[2]}ã®ã‚¯ãƒ©ã‚¹ã‚¿åˆ†é¡")
        plt.close()
        print(self.df.groupby("ã‚¯ãƒ©ã‚¹ã‚¿").mean())

        plt.scatter(self.df[self.columns[2]], self.df[self.columns[0]], c=self.df["ã‚¯ãƒ©ã‚¹ã‚¿"], cmap="viridis")
        plt.xlabel(self.columns[2])
        plt.ylabel(self.columns[0])
        plt.title(f"{self.columns[2]}ã¨{self.columns[0]}ã®ã‚¯ãƒ©ã‚¹ã‚¿åˆ†é¡")
        plt.close()
        print(self.df.groupby("ã‚¯ãƒ©ã‚¹ã‚¿").mean())

        #ã‚¹ã‚³ã‚¢å‘ä¸Šã®è¦å› åˆ†æï¼ˆç‰¹å¾´é‡é‡è¦åº¦è©•ä¾¡ï¼‰
        X = self.df[self.get_feature_columns_for_regression()]
        y = self.df["ã‚¹ã‚³ã‚¢"]
        
        model = DecisionTreeRegressor()
        model.fit(X, y)

        print("ç‰¹å¾´é‡ã®å½±éŸ¿åº¦:", model.feature_importances_)


class MyTypingProcessor(TypingDataProcessor):
    """ MyTyping ã®å‡¦ç† """

    def __init__(self, file_path, sheet_name):
        columns = ["å¹³å‡é€Ÿåº¦", "ã‚¹ã‚³ã‚¢", "æ­£æ‰“ç‡"]
        super().__init__(file_path, sheet_name, usecols="B:D", columns=columns, image_name="mytyping.png")
    def process_data(self):
        """ æ­£æ‰“ç‡ã®è¨ˆç®— """
        self.df["æ­£æ‰“ç‡"] = self.df["æ­£æ‰“ç‡"] * 100

class SushidaProcessor(TypingDataProcessor):
    """ å¯¿å¸æ‰“ ã®å‡¦ç† """

    def __init__(self, file_path, sheet_name):
        columns = ["ç·æ­£æ‰“æ•°", "ã‚¹ã‚³ã‚¢", "æ­£æ‰“ç‡"]
        image_name = f"{sheet_name}.png"  # âœ… ã‚·ãƒ¼ãƒˆåã«å¿œã˜ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´
        super().__init__(file_path, sheet_name, usecols="B:D", columns=columns, image_name=image_name)

    def process_data(self):
        """ æ­£æ‰“ç‡ã¨ã‚¹ã‚³ã‚¢ã®è¨ˆç®— """
        self.df["æ­£æ‰“ç‡"] = (self.df["æ­£ã—ãæ‰“ã£ãŸã‚­ãƒ¼"] / (self.df["æ­£ã—ãæ‰“ã£ãŸã‚­ãƒ¼"] + self.df["ãƒŸã‚¹"]) * 100).round(1)
        self.df["ã‚¹ã‚³ã‚¢"] = ((self.df["æ­£ã—ãæ‰“ã£ãŸã‚­ãƒ¼"] - self.df["ãƒŸã‚¹"]) / (90 if self.sheet_name == "sushida5000" else 120) * 1000).round(0).astype(int)
        self.df["ç·æ­£æ‰“æ•°"] = self.df["æ­£ã—ãæ‰“ã£ãŸã‚­ãƒ¼"]
        self.df = self.df[["ç·æ­£æ‰“æ•°", "æ­£æ‰“ç‡", "ã‚¹ã‚³ã‚¢"]]

# sushida5000ã®ã‚¯ãƒ©ã‚¹å®Ÿè¡Œ
file_path = "record.xlsx"
processor_sushida_5000 = SushidaProcessor(file_path, "sushida5000")
processor_sushida_5000.make_excel()
processor_sushida_5000.plot_graphs()  
processor_sushida_5000.plot_summary_table()
processor_sushida_5000.analysis_trend_related()
processor_sushida_5000.analysis_structure_features()

# sushida10000ã®ã‚¯ãƒ©ã‚¹å®Ÿè¡Œ
processor_sushida_10000 = SushidaProcessor(file_path, "sushida10000")
processor_sushida_10000.plot_graphs()  
processor_sushida_10000.plot_summary_table()
processor_sushida_10000.analysis_trend_related()
processor_sushida_10000.analysis_structure_features()

# mytypingã®ã‚¯ãƒ©ã‚¹å®Ÿè¡Œ
processor_mytyping = MyTypingProcessor(file_path, "mytyping")
processor_mytyping.plot_graphs()  
processor_mytyping.plot_summary_table()
processor_mytyping.analysis_trend_related()
processor_mytyping.analysis_structure_features()